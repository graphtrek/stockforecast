{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graphtrek_07.ipynb",
      "provenance": [],
      "mount_file_id": "11Jv6x_dRW7z_I4eyLToRD1H4P_6rRKog",
      "authorship_tag": "ABX9TyM7OJRu4KTvWI8q4to6D2mg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphtrek/stockforecast/blob/main/graphtrek_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZPC3Z9u3evF"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MAE\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow import keras\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import os, time\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "from pandas.tseries.offsets import CustomBusinessDay\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MAE\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow import keras\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import os, time\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "from pandas.tseries.offsets import CustomBusinessDay\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKYStAEQ3mh6"
      },
      "source": [
        "ticker = \"QQQ\"\n",
        "look_back = 5 #  number of past days we want to use to predict 1 day in the future.\n",
        "max_data_size = 730 # ~2 years\n",
        "split_percent = 0.90 # use 90% of the data  for train\n",
        "INFO = 1\n",
        "DEBUG = 2\n",
        "TRACE = 3\n",
        "print_level = DEBUG \n",
        "indicators_model_file_path = '/content/drive/MyDrive/models/'+ticker+'_indicators_07.h5'\n",
        "nr_of_indicators = 1\n",
        "look_forward = 1\n",
        "epochs = 200\n",
        "learning_rate=0.0001\n",
        "num_prediction = look_back * 3\n",
        "np.random.seed(42)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPJ9HBOO3-2-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be91a957-db10-49be-9e29-7a53e5b0c656"
      },
      "source": [
        "rsi_url = 'https://www.alphavantage.co/query?function=RSI&datatype=json&symbol='+ticker+'&interval=daily&time_period=14&series_type=open&apikey=3F4URDEKOPLFH25T'\n",
        "print(rsi_url)\n",
        "rsi_api_response = pd.read_json(rsi_url)\n",
        "#print(rsi_api_response)\n",
        "rsi_api_data = rsi_api_response['Technical Analysis: RSI']\n",
        "#print(rsi_api_data)\n",
        "rsi_api_data = rsi_api_data.drop(\n",
        "    index=['1: Symbol','2: Indicator','3: Last Refreshed','4: Interval','5: Time Period','6: Series Type','7: Time Zone']);\n",
        "#print(rsi_api_data)\n",
        "\n",
        "rsi_data = []\n",
        "indicators_lstm_data = []\n",
        "for key, value in rsi_api_data.items():\n",
        "  date = key\n",
        "  rsi = float(value.get('RSI'))\n",
        "  rsi_data.append([date,rsi])\n",
        "  indicators_lstm_data.append([rsi])\n",
        "\n",
        "#print('rsi_data:', rsi_data)  \n",
        "last_date =  str(rsi_data[0][0])\n",
        "\n",
        "if max_data_size < len(rsi_data):\n",
        "  rsi_data = np.flip(rsi_data[:max_data_size],axis=0)\n",
        "  indicators_lstm_data = np.flip(indicators_lstm_data[:max_data_size],axis=0)\n",
        "else:\n",
        "  rsi_data = np.flip(rsi_data,axis=0)\n",
        "  indicators_lstm_data = np.flip(indicators_lstm_data,axis=0)\n",
        "\n",
        "first_rsi_data =  str(rsi_data[0])\n",
        "last_rsi_data =  str(rsi_data[-1])\n",
        "print('rsi_data_length:', len(rsi_data), 'first_rsi_data:', first_rsi_data, 'last_rsi_data:', last_rsi_data)  "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.alphavantage.co/query?function=RSI&datatype=json&symbol=QQQ&interval=daily&time_period=14&series_type=open&apikey=3F4URDEKOPLFH25T\n",
            "rsi_data_length: 730 first_rsi_data: ['2018-12-19' '39.6284'] last_rsi_data: ['2021-11-10' '64.804']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYTx2W6N4JIM"
      },
      "source": [
        "rsi_df = pd.DataFrame(rsi_data,columns=['Date','RSI'])\n",
        "\n",
        "split = int(split_percent*len(rsi_data))\n",
        "if len(rsi_data) - split < look_back:\n",
        "  split = look_back\n",
        "split\n",
        "\n",
        "\n",
        "rsi_df_train = rsi_df.iloc[:split]\n",
        "rsi_df_test = rsi_df.iloc[split:]\n",
        "\n",
        "indicators_lstm_train_data = indicators_lstm_data[:split]\n",
        "indicators_lstm_test_data = indicators_lstm_data[split:]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oRtthul4Pyj"
      },
      "source": [
        "np.set_printoptions(formatter={'float': '{: 0.12f}'.format})\n",
        "\n",
        "indicators_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "indicators_scaler = indicators_scaler.fit(indicators_lstm_data)\n",
        "\n",
        "indicators_lstm_train_data_scaled = indicators_scaler.transform(indicators_lstm_train_data)\n",
        "if print_level >= TRACE:\n",
        "  print(indicators_lstm_train_data_scaled[:look_back+1])\n",
        "  print(indicators_lstm_train_data_scaled.shape)\n",
        "\n",
        "indicators_lstm_test_data_scaled = indicators_scaler.transform(indicators_lstm_test_data)\n",
        "if print_level >= TRACE:\n",
        "  print(indicators_lstm_test_data_scaled[:look_back+1])\n",
        "  print(indicators_lstm_test_data_scaled.shape)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmmqy0nc4Slr"
      },
      "source": [
        "indicators_train_generator = TimeseriesGenerator(indicators_lstm_train_data_scaled, indicators_lstm_train_data_scaled, sampling_rate=1, length=look_back, batch_size=64)\n",
        "\n",
        "if print_level >= TRACE:\n",
        "  print('Samples: %d' % len(indicators_train_generator))\n",
        "  # print each sample\n",
        "  for i in range(2):\n",
        "    x, y = indicators_train_generator[i]\n",
        "    print('%s => %s' % (x, y))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFQnXfRp6tVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14bc054-602b-4f32-e641-d8b361c9abcd"
      },
      "source": [
        "indicators_model = None\n",
        "try:\n",
        "  indicators_model = keras.models.load_model(indicators_model_file_path)\n",
        "  modified = os.path.getmtime(indicators_model_file_path)\n",
        "\n",
        "  print(pd.to_datetime(last_date).date() - datetime.fromtimestamp(modified).date() )\n",
        "  print('Loaded', indicators_model_file_path , ' model train date:',datetime.fromtimestamp(modified).date() , 'last date:', last_date)\n",
        "except:\n",
        "  indicators_model = None\n",
        "  print('Model ' + indicators_model_file_path + ' does not exists.')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:00:00\n",
            "Loaded /content/drive/MyDrive/models/QQQ_indicators_07.h5  model train date: 2021-11-10 last date: 2021-11-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r59DQEiZ0u18"
      },
      "source": [
        "if indicators_model is None:\n",
        "  indicators_model = Sequential()\n",
        "  indicators_model.add(LSTM(units=50, activation='tanh', input_shape=(look_back, nr_of_indicators), return_sequences=True))\n",
        "  indicators_model.add(Dropout(0.2))\n",
        "  indicators_model.add(LSTM(units=50, return_sequences=True, activation=\"tanh\"))\n",
        "  indicators_model.add(Dropout(0.2))\n",
        "  indicators_model.add(LSTM(units=50, return_sequences=True, activation=\"tanh\"))\n",
        "  indicators_model.add(Dropout(0.2))\n",
        "  indicators_model.add(LSTM(units=50, activation=\"tanh\"))\n",
        "  indicators_model.add(Dropout(0.2))\n",
        "  indicators_model.add(Dense(nr_of_indicators))\n",
        "\n",
        "  indicators_model.compile(\n",
        "      loss=MAE,\n",
        "      optimizer=Adam(learning_rate=learning_rate),\n",
        "      metrics=[\"mae\"]\n",
        "  )\n",
        "    \n",
        "  #model.summary()\n",
        "  print('Model ' + indicators_model_file_path + ' compiled.')\n",
        "\n",
        "  indicators_modelo = indicators_model.fit(indicators_train_generator, epochs=epochs, verbose=0 )\n",
        "  \n",
        "  indicators_model.save(indicators_model_file_path)\n",
        "  print('Saved model ' + indicators_model_file_path)\n",
        "\n",
        "  if print_level >= DEBUG:\n",
        "    plt.plot(indicators_modelo.history['loss'])\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.show()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkdpY8eE4XlZ",
        "outputId": "9db2dbdb-8a14-46cb-be4c-9f66c5f6ec2e"
      },
      "source": [
        "indicators_test_generator = TimeseriesGenerator(indicators_lstm_test_data_scaled, indicators_lstm_test_data_scaled,sampling_rate=1, length=look_back, batch_size=look_back)\n",
        "\n",
        "print('Samples: %d' % len(indicators_test_generator))\n",
        "# print each sample\n",
        "if print_level >= TRACE:\n",
        "  for i in range(2):\n",
        "    x, y = indicators_test_generator[i]\n",
        "    print('%s => %s' % (x, y))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAS1RHA1Mn10",
        "outputId": "b38fc183-85b0-48c7-9b22-c4d109ae5920"
      },
      "source": [
        "#Make prediction\n",
        "indicators_prediction_scaled = indicators_model.predict(indicators_test_generator)\n",
        "\n",
        "if print_level >= DEBUG:\n",
        "  np.set_printoptions(formatter={'float': '{: 0.12f}'.format})\n",
        "  print(indicators_prediction_scaled[:5])\n",
        "\n",
        "indicators_prediction = indicators_scaler.inverse_transform(indicators_prediction_scaled)\n",
        "\n",
        "if print_level >= DEBUG:\n",
        "  np.set_printoptions(formatter={'float': '{: 0.2f}'.format})\n",
        "  print('indicators_prediction shape:',indicators_prediction.shape)\n",
        "\n",
        "  for x in range(look_back + 1):\n",
        "    print('pred:',indicators_prediction[x], 'test:', indicators_lstm_test_data[x])\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.622155189514]\n",
            " [ 0.647036314011]\n",
            " [ 0.648983716965]\n",
            " [ 0.666976690292]\n",
            " [ 0.677875638008]]\n",
            "indicators_prediction shape: (68, 1)\n",
            "pred: [ 60.31] test: [ 57.05]\n",
            "pred: [ 61.72] test: [ 61.65]\n",
            "pred: [ 61.83] test: [ 59.85]\n",
            "pred: [ 62.85] test: [ 61.65]\n",
            "pred: [ 63.47] test: [ 63.32]\n",
            "pred: [ 63.38] test: [ 63.56]\n"
          ]
        }
      ]
    }
  ]
}