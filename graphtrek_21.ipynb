{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graphtrek_20.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphtrek/stockforecast/blob/main/graphtrek_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqMCA9YoriWx",
        "outputId": "042cf765-b471-42c9-bc6f-237ec77f5234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.68)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.10)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.7.1)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.0.9)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (5.5.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly) (8.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n",
            "Requirement already satisfied: ta in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ta) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ta) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ta) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# install necessary modules\n",
        "!pip install yfinance\n",
        "!pip install plotly\n",
        "!pip install ta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time\n",
        "import yfinance as yf\n",
        "import requests\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "from pathlib import Path\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "import pandas as pd\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "from pandas.tseries.offsets import CustomBusinessDay\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MAE\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "from ta.trend import MACD\n",
        "from ta.momentum import StochasticOscillator\n",
        "from ta.momentum import RSIIndicator\n",
        "\n",
        "\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "MIfXZ81VrrqB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# method 1: fractal candlestick pattern\n",
        "\n",
        "def get_stock_price(ticker, from_date):\n",
        "  df = yf.download(ticker.ticker, start=from_date, interval=\"1d\")\n",
        "  #df = df.rename(columns={\"Close\": \"Close1\", \"Adj Close\": \"Close\"})\n",
        "  \n",
        "  #ticker = yf.Ticker(symbol)\n",
        "\n",
        "  #df = ticker.history(start=from_date, interval=\"1d\")\n",
        "  #print(df.info())\n",
        "  df['Date'] = pd.to_datetime(df.index)\n",
        "  #df['Date'] = df['Date'].apply(mpl_dates.date2num)\n",
        "  #df = df.loc[:,['Date', 'Open', 'High', 'Low', 'Close']]\n",
        "  df['MA21'] = df['Close'].ewm(span=21, adjust=False).mean()\n",
        "  df['MA50'] = df['Close'].rolling(window=50).mean()\n",
        "  df['MA100'] = df['Close'].rolling(window=100).mean()\n",
        "  df['MA200'] = df['Close'].rolling(window=200).mean()\n",
        "  return df\n",
        "\n",
        "def is_support(df,i):\n",
        "  cond1 = df['Low'][i] < df['Low'][i-1] \n",
        "  cond2 = df['Low'][i] < df['Low'][i+1] \n",
        "  cond3 = df['Low'][i+1] < df['Low'][i+2] \n",
        "  cond4 = df['Low'][i-1] < df['Low'][i-2]\n",
        "  return (cond1 and cond2 and cond3 and cond4)\n",
        "\n",
        "def is_resistance(df,i):\n",
        "  cond1 = df['High'][i] > df['High'][i-1] \n",
        "  cond2 = df['High'][i] > df['High'][i+1] \n",
        "  cond3 = df['High'][i+1] > df['High'][i+2] \n",
        "  cond4 = df['High'][i-1] > df['High'][i-2]\n",
        "  return (cond1 and cond2 and cond3 and cond4)\n",
        "\n",
        "def is_far_from_level(value, levels, df):\n",
        "    ave =  np.mean(df['High'] - df['Low'])\n",
        "    return np.sum([abs(value - level) < ave for level in levels]) == 0\n",
        "\n",
        "def findNearestGreaterThan(searchVal, inputData):\n",
        "    diff = inputData - searchVal\n",
        "    diff[diff<0] = np.inf\n",
        "    idx = diff.argmin()\n",
        "    return inputData[idx]\n",
        "\n",
        "\n",
        "def findNearestLessThan(searchVal, inputData):\n",
        "    diff = inputData - searchVal\n",
        "    diff[diff>0] = -np.inf\n",
        "    idx = diff.argmax()\n",
        "    return inputData[idx]\n",
        "\n",
        "def indicators(chart_df):\n",
        "  # MACD\n",
        "  macd = MACD(close=chart_df['Close'], \n",
        "            window_slow=26,\n",
        "            window_fast=12, \n",
        "            window_sign=9)\n",
        "  # stochastics\n",
        "  stoch = StochasticOscillator(high=chart_df['High'],\n",
        "                             close=chart_df['Close'],\n",
        "                             low=chart_df['Low'],\n",
        "                             window=14, \n",
        "                             smooth_window=3)\n",
        "\n",
        "  rsi = RSIIndicator(close=chart_df['Close'], window=14)\n",
        "  return macd, stoch, rsi"
      ],
      "metadata": {
        "id": "jyYPSEVcsEFj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_levels(chart_df):\n",
        "  levels = []\n",
        "  low = 0\n",
        "  high = np.round(chart_df['Close'].max(),1)\n",
        "  for i in range(2,len(chart_df)-2):\n",
        "    if is_support(chart_df,i):\n",
        "      low = chart_df['Low'][i]\n",
        "    if is_far_from_level(low, levels, chart_df):\n",
        "      levels.append(low)\n",
        "    elif is_resistance(chart_df,i):\n",
        "      high = chart_df['High'][i]\n",
        "    if is_far_from_level(high, levels, chart_df):\n",
        "      levels.append(high)\n",
        "  levels = sorted(levels, reverse=True)\n",
        "\n",
        "  last_day_df = chart_df[-1:]\n",
        "  close_price = np.round(last_day_df['Close'][0],1)\n",
        "\n",
        "  min_level = np.round(findNearestLessThan(close_price,levels),1)\n",
        "  if(min_level > close_price):\n",
        "    min_level = np.round(close_price * 0.8,1)\n",
        "\n",
        "  max_level = np.round(findNearestGreaterThan(close_price,levels),1)\n",
        "  if(max_level < close_price):\n",
        "    max_level = np.round(close_price * 1.2,1)\n",
        "\n",
        "#  print('close_price',close_price,'min_level:',min_level,'max_level:', max_level)\n",
        "  return levels, min_level, max_level"
      ],
      "metadata": {
        "id": "cBDM1rHHKZSf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def options_chain(ticker):\n",
        "\n",
        "    #tk = yf.Ticker(symbol)\n",
        "    # Expiration dates\n",
        "    exps = ticker.options\n",
        "\n",
        "    # Get options for each expiration\n",
        "    options = pd.DataFrame()\n",
        "    for e in exps:\n",
        "        opt = ticker.option_chain(e)\n",
        "        opt = pd.DataFrame().append(opt.calls).append(opt.puts)\n",
        "        opt['expirationDate'] = e\n",
        "        options = options.append(opt, ignore_index=True)\n",
        "\n",
        "    # Bizarre error in yfinance that gives the wrong expiration date\n",
        "    # Add 1 day to get the correct expiration date\n",
        "    options['expirationDate'] = pd.to_datetime(options['expirationDate'])\n",
        "    options.insert(0,'dte',(options['expirationDate'] - datetime.today()).dt.days + 1)\n",
        "    options['expirationDate'] = options['expirationDate'].dt.date\n",
        "    # Boolean column if the option is a CALL x : True if (x > 10 and x < 20) else False\n",
        "    options.insert(1,'CALL',options['contractSymbol'].str[4:].apply(lambda x: \"C\" in x))\n",
        "    \n",
        "    options[['bid', \n",
        "             'ask', \n",
        "             'strike', \n",
        "             'lastPrice', \n",
        "             'volume',\n",
        "             'change',\n",
        "             'percentChange',\n",
        "             'openInterest',\n",
        "             'impliedVolatility']] = options[[\n",
        "                                   'bid', \n",
        "                                   'ask', \n",
        "                                   'strike',\n",
        "                                   'lastPrice',\n",
        "                                   'volume',\n",
        "                                   'change',\n",
        "                                   'percentChange',\n",
        "                                   'openInterest',\n",
        "                                   'impliedVolatility']].apply(pd.to_numeric)\n",
        "    \n",
        "    options['spread%'] = np.round(100 - ((options['bid'] / options['ask']) * 100),1) # Calculate the midpoint of the bid-ask\n",
        "    \n",
        "    # Drop unnecessary and meaningless columns\n",
        "    #options = options.drop(columns = ['contractSize', 'currency', 'change', 'percentChange', 'lastTradeDate', 'lastPrice'])\n",
        "\n",
        "    return options"
      ],
      "metadata": {
        "id": "R2FEIo4xTL-w"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_level_optionInterests(ticker,close_price,min_level,max_level, dte_min, dte_max):\n",
        "  options_df = options_chain(ticker)\n",
        "  options_df['impliedVolatility'] = np.round(options_df['impliedVolatility'],2)\n",
        "  options_df['percentChange'] = np.round(options_df['percentChange'],2)\n",
        "  #expirationDates = options_df['expirationDate'].unique()\n",
        "  #print(sorted(expirationDates))\n",
        "\n",
        "  #PUT_options_df = pd.DataFrame()\n",
        "  #CALL_options_df = pd.DataFrame()\n",
        "\n",
        "  #for key, value in options_df.items():\n",
        "  #  date = key\n",
        "  #  rsi = float(value.get('RSI'))\n",
        "  #  rsi_data.append([date,rsi])\n",
        "#  print('PUT OPTIONS', 'CLOSE PRICE:',close_price, 'SUPPORT -15%:', np.round(min_level * 0.85,2), 'RESISTANCE +15%:', np.round(max_level * 1.15,2))\n",
        "  PUT_options_df = options_df.query('CALL == False and strike>' + str(min_level * 0.85) + ' and strike<' + str(max_level * 1.15) + ' and dte>' + str(dte_min) + ' and dte<' + str(dte_max))\n",
        "  put_max_openInterest_index = PUT_options_df[\"openInterest\"].idxmax()\n",
        "  put_max_volume_index = PUT_options_df[\"volume\"].idxmax()\n",
        "  PUT_options_to_return_df = PUT_options_df.loc[put_max_openInterest_index:put_max_openInterest_index]\n",
        "  PUT_options_to_return_df = PUT_options_to_return_df.append(PUT_options_df.loc[put_max_volume_index:put_max_volume_index])\n",
        "  PUT_options_to_return_df = PUT_options_to_return_df.drop(columns = ['contractSize', 'currency','change','percentChange', 'lastTradeDate', 'lastPrice', 'inTheMoney','contractSymbol']) \n",
        "  \n",
        "#  print(tabulate(PUT_options_to_return_df, headers = 'keys', tablefmt = 'psql'))\n",
        "\n",
        "#  print('CALL OPTIONS', 'CLOSE PRICE:',close_price, 'SUPPORT -15%:', np.round(min_level * 0.85,2), 'RESISTANCE +15%:', np.round(max_level * 1.15,2))\n",
        "  CALL_options_df = options_df.query('CALL == True and strike>' + str(min_level * 0.85) + ' and strike<' + str(max_level * 1.15) + ' and dte>' + str(dte_min) + ' and dte<' + str(dte_max))\n",
        "  call_max_openInterest_index = CALL_options_df[\"openInterest\"].idxmax()\n",
        "  call_max_volume_index = CALL_options_df[\"volume\"].idxmax()\n",
        "  CALL_options_to_return_df = CALL_options_df.loc[call_max_openInterest_index:call_max_openInterest_index]\n",
        "  CALL_options_to_return_df = CALL_options_to_return_df.append(CALL_options_df.loc[call_max_volume_index:call_max_volume_index])\n",
        "  CALL_options_to_return_df = CALL_options_to_return_df.drop(columns = ['contractSize', 'currency', 'change','percentChange', 'lastTradeDate', 'lastPrice', 'inTheMoney','contractSymbol']) \n",
        "#  print(call_max_openInterest_index,tabulate(CALL_options_to_return_df, headers = 'keys', tablefmt = 'psql'))\n",
        "  return PUT_options_to_return_df, CALL_options_to_return_df"
      ],
      "metadata": {
        "id": "fbz2SVTOTwki"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_chart(ticker, df, days):\n",
        "  last_day_df = df[-1:]\n",
        "  last_date = last_day_df['Date'].index[0].date()\n",
        "  close_price = np.round(last_day_df['Close'][0],1)\n",
        "\n",
        "  ath = np.round(df['Close'].max(),1)\n",
        "  discount = np.round(ath - close_price,1)\n",
        "  discount_percent = np.round((discount / close_price) * 100, 1)\n",
        "  \n",
        "  chart_df = df.tail(days)\n",
        "\n",
        "  macd, soch, rsi = indicators(chart_df)\n",
        "  levels, min_level, max_level = calculate_levels(chart_df)\n",
        "\n",
        "  min_level_0_85 = np.round(min_level * 0.85,2)\n",
        "  min_level_0_85_discount = np.round(min_level_0_85 - close_price)\n",
        "  min_level_0_85_discount_percent =  np.round((min_level_0_85_discount / close_price) * 100, 1)\n",
        "\n",
        "  max_level_1_15 = np.round(max_level * 1.15,2)\n",
        "  max_level_1_15_discount = np.round(max_level_1_15 - close_price)\n",
        "  max_level_1_15_discount_percent = np.round((max_level_1_15_discount / close_price) * 100, 1)\n",
        "\n",
        "  options_df = pd.DataFrame()\n",
        "  near_PUT_options_df, near_CALL_options_df = find_level_optionInterests(ticker,close_price,min_level_0_85,max_level_1_15, -1, 33)\n",
        "  far_PUT_options_df, far_CALL_options_df = find_level_optionInterests(ticker,close_price,min_level_0_85,max_level_1_15, 33, 333)\n",
        "\n",
        "  options_df = options_df.append(near_PUT_options_df)\n",
        "  options_df = options_df.append(far_PUT_options_df)\n",
        "  options_df = options_df.append(near_CALL_options_df)\n",
        "  options_df = options_df.append(far_CALL_options_df)\n",
        "  options_df.insert(3,'Price',close_price)\n",
        "  options_df = options_df.sort_values(by=['dte'])\n",
        "\n",
        "  min_level_discount = np.round(min_level - close_price)\n",
        "  min_level_discount_percent = np.round((min_level_discount / close_price) * 100, 1)\n",
        "  \n",
        "  max_level_discount = np.round(max_level - close_price)\n",
        "  max_level_discount_percent = np.round((max_level_discount / close_price) * 100, 1)\n",
        "  \n",
        "  tradingview_link = '<a href=\"https://in.tradingview.com/chart/66XmQfYy/?symbol=' + ticker.ticker +'\">' +  ticker.ticker + ' ' + str(last_date)  +'</a> '\n",
        "  seeking_alpha_link = '<a href=\"https://seekingalpha.com/symbol/'+ ticker.ticker +'\"> Seeking Alpha </a> '\n",
        "  google_news_link = '<a href=\"https://news.google.com/search?for=' + ticker.ticker + '+stock when:7d&hl=en-US&gl=US&ceid=US%3Aen\"> Google News </a> '\n",
        "  twitter_link = '<a href=\"https://twitter.com/search?q=$' + ticker.ticker + '%20stock&src=typed_query&f=live\"> Twitter </a> '\n",
        "\n",
        "  title = '<b>' + tradingview_link + '</b> ' + seeking_alpha_link + google_news_link + twitter_link \n",
        "  title += '<br>'\n",
        "  title += '<b>Close Price:</b>' + str(close_price) + ' <b>ATH:</b>' + str(ath) + ' <b>Discount:</b>' + str(discount) + ' (' + str(discount_percent) + '%)'\n",
        "  title += '<br>'\n",
        "  title += '<b>Support:</b>' + str(min_level) + ' ('+str(min_level_discount_percent)+'%) ' \n",
        "  title += '<b>Close Price:</b>' + str(close_price) + ' ' \n",
        "  title += '<b>Resistance:</b>' + str(max_level) + ' ('+str(max_level_discount_percent)+'%) '\n",
        "  title += '<br>' \n",
        "  title += '<b>Support -15%:</b>' + str(min_level_0_85) + ' (' + str(min_level_0_85_discount_percent) + '%) '\n",
        "  title += '<b>Close Price:</b>' + str(close_price) + ' ' \n",
        "  title += '<b>Resistance +15%:</b>' + str(max_level_1_15) + ' (' + str(max_level_1_15_discount_percent) +  '%) '\n",
        "  \n",
        "  # add subplot properties when initiliazing fig variable\n",
        "  fig = make_subplots(rows=5, cols=1, shared_xaxes=True,\n",
        "                    vertical_spacing=0.01, \n",
        "                    row_heights=[0.26,0.34,0.1,0.15,0.15],\n",
        "                    subplot_titles=[title],\n",
        "                    specs=[\n",
        "                           [{\"type\": \"table\"}],\n",
        "                           [{\"type\": \"candlestick\"}],\n",
        "                           [{\"type\": \"bar\"}],\n",
        "                           [{\"type\": \"scatter\"}],\n",
        "                           [{\"type\": \"scatter\"}]\n",
        "                           ])\n",
        "\n",
        "  fig.update_layout(\n",
        "      height=900, width=1200, \n",
        "      showlegend=True,\n",
        "      dragmode= 'pan', \n",
        "      margin=go.layout.Margin(\n",
        "          l=20, #left margin\n",
        "          r=20, #right margin\n",
        "          b=20, #bottom margin\n",
        "          t=100  #top margin\n",
        "      ))\n",
        "\n",
        "\n",
        "  fig.add_trace(\n",
        "      go.Table(\n",
        "        header=dict(values=list(options_df.columns),\n",
        "                fill_color='paleturquoise',\n",
        "                font=dict(color='black', size=12),\n",
        "                align='left'),\n",
        "        cells=dict(values=options_df.transpose().values.tolist(),\n",
        "               fill_color='lavender',\n",
        "               align='left')\n",
        "        ),row=1, col=1)\n",
        "  \n",
        "  # Plot OHLC on 1st subplot (using the codes from before)\n",
        "  fig.add_trace(go.Candlestick(x=chart_df.index,\n",
        "                             open=chart_df['Open'],\n",
        "                             high=chart_df['High'],\n",
        "                             low=chart_df['Low'],\n",
        "                             close=chart_df['Close'], \n",
        "                             name=ticker.ticker,\n",
        "                             showlegend=True), row=2, col=1)\n",
        "  \n",
        "\n",
        "  # add moving average traces\n",
        "  fig.add_trace(go.Scatter(x=chart_df.index, \n",
        "                         y=chart_df['MA21'], \n",
        "                         line=dict(color='green', width=2), \n",
        "                         name='MA 21'), row=2, col=1)\n",
        "  fig.add_trace(go.Scatter(x=chart_df.index, \n",
        "                         y=chart_df['MA50'], \n",
        "                         line=dict(color='blue', width=2), \n",
        "                         name='MA 50'), row=2, col=1)\n",
        "  fig.add_trace(go.Scatter(x=chart_df.index, \n",
        "                         y=chart_df['MA100'], \n",
        "                         line=dict(color='orange', width=2), \n",
        "                         name='MA 100'), row=2, col=1)\n",
        "  fig.add_trace(go.Scatter(x=chart_df.index, \n",
        "                         y=chart_df['MA200'], \n",
        "                         line=dict(color='red', width=2), \n",
        "                         name='MA 200'), row=2, col=1)\n",
        "\n",
        "\n",
        "  start_date = \"2021-06-01\"\n",
        "  end_date = \"2022-01-31\"\n",
        "  zoom_df = chart_df.iloc[chart_df.index >= start_date]\n",
        "  y_zoom_max = zoom_df[\"High\"].max()\n",
        "  y_zoom_min = zoom_df[\"Low\"].min()\n",
        "\n",
        "  ath_percent = 0\n",
        "  \n",
        "  for idx, level in  enumerate(levels):\n",
        "      percent = 0\n",
        "      if idx == 0:\n",
        "        ath = level\n",
        "      current_level = level\n",
        "      if idx > 0:\n",
        "        prev_level = levels[idx-1]\n",
        "        diff = prev_level - current_level\n",
        "        ath_diff = ath - current_level\n",
        "        percent = (diff / current_level) * 100\n",
        "        ath_percent =  (ath_diff / current_level) * 100\n",
        "      if level <= (min_level * 0.85) or level >= (max_level * 1.15):\n",
        "        line_color = 'rgba(100, 10, 100, 0.2)'\n",
        "      else:\n",
        "        line_color = 'rgba(200, 20, 200, 1)'\n",
        "      fig.add_trace(go.Scatter(\n",
        "          x = [chart_df.index.min(), chart_df.index.max()],\n",
        "          y = [level, level],\n",
        "          mode=\"lines+text\",\n",
        "          name=\"Lines and Text\",\n",
        "          showlegend=False,\n",
        "          text=['','$' + str(np.round(current_level,1)) + ' (' + str(np.round(percent,1)) + '% disc:' + str(np.round(ath_percent,1))+ '%)',''],\n",
        "          textposition=\"top right\",\n",
        "          line = dict(shape = 'linear', color = line_color, dash = 'dash', width=1)\n",
        "        ), row=2, col=1)\n",
        "\n",
        "\n",
        "  # Plot volume trace on 3d row \n",
        "  colors = ['green' if row['Open'] - row['Close'] >= 0 \n",
        "            else 'red' for index, row in chart_df.iterrows()]\n",
        "  fig.add_trace(go.Bar(x=chart_df.index, \n",
        "                      y=chart_df['Volume'],\n",
        "                      marker_color=colors,\n",
        "                      name='Volume'\n",
        "                      ), row=3, col=1)\n",
        "\n",
        "\n",
        "  fig.add_trace(go.Scatter(x=chart_df.index,\n",
        "                          y=rsi.rsi(),\n",
        "                          line=dict(color='black', width=2),\n",
        "                          name='RSI(14)'\n",
        "                          ), row=4, col=1)\n",
        "\n",
        "  fig.add_trace(go.Scatter(\n",
        "          x = [np.min(chart_df.index), np.max(chart_df.index)],\n",
        "          y = [70, 70],\n",
        "          mode = \"lines\",\n",
        "          line = dict(shape = 'linear', color = 'rgb(100, 10, 100)', dash = 'dash'),\n",
        "          name = 'RSI(14) over bought'\n",
        "      ),row=4, col=1)\n",
        "\n",
        "  fig.add_trace(go.Scatter(\n",
        "          x = [np.min(chart_df.index), np.max(chart_df.index)],\n",
        "          y = [50, 50],\n",
        "          mode = \"lines\",\n",
        "          line = dict(shape = 'linear', color = 'rgb(10, 12, 240)', dash = 'dash'),\n",
        "          name='RSI(14) Neutral'\n",
        "      ),row=4, col=1)\n",
        "\n",
        "  fig.add_trace(go.Scatter(\n",
        "          x = [np.min(chart_df.index), np.max(chart_df.index)],\n",
        "          y = [30, 30],\n",
        "          mode = \"lines\",\n",
        "          line = dict(shape = 'linear', color = 'rgb(10, 120, 24)', dash = 'dash'),\n",
        "          name='RSI(14) over sold'\n",
        "      ),row=4, col=1)\n",
        "\n",
        "  # Plot MACD trace on 3rd row\n",
        "  colors = ['green' if val >= 0 \n",
        "            else '#FF5733' for val in macd.macd_diff()]\n",
        "  fig.add_trace(go.Bar(x=chart_df.index, \n",
        "                      y=macd.macd_diff(),\n",
        "                      marker_color=colors,\n",
        "                      name='MACD diff'\n",
        "                      ), row=5, col=1)\n",
        "  fig.add_trace(go.Scatter(x=chart_df.index,\n",
        "                          y=macd.macd(),\n",
        "                          line=dict(color='orange', width=2),\n",
        "                          name='MACD'\n",
        "                          ), row=5, col=1)\n",
        "  fig.add_trace(go.Scatter(x=chart_df.index,\n",
        "                          y=macd.macd_signal(),\n",
        "                          line=dict(color='blue', width=1),\n",
        "                          name='MACD signal'\n",
        "                          ), row=5, col=1)\n",
        "\n",
        "\n",
        "  fig.update_xaxes(type=\"date\", range=[start_date, end_date])\n",
        "  fig.update_yaxes(range=[y_zoom_min,y_zoom_max], row=2, col=1)\n",
        "\n",
        "#  for idx, level in  enumerate(levels):\n",
        "#    fig.add_hline(level,row=2, col=1)\n",
        "\n",
        "  fig.update_layout(xaxis_rangeslider_visible=False)\n",
        "  # removing all empty dates\n",
        "  # build complete timeline from start date to end date\n",
        "  dt_all = pd.date_range(start=chart_df.index[0],end=chart_df.index[-1])\n",
        "  # retrieve the dates that ARE in the original datset\n",
        "  dt_obs = [d.strftime(\"%Y-%m-%d\") for d in pd.to_datetime(chart_df.index)]\n",
        "  # define dates with missing values\n",
        "  dt_breaks = [d for d in dt_all.strftime(\"%Y-%m-%d\").tolist() if not d in dt_obs]\n",
        "\n",
        "  fig.update_layout(xaxis_rangebreaks=[dict(values=dt_breaks)])\n",
        "  fig.update_yaxes(showspikes=True, spikemode='across', spikesnap='cursor',spikedash='dash')\n",
        "  fig.update_xaxes(showspikes=True, spikemode='across', spikesnap='cursor', spikedash='dash')\n",
        "  config = dict({'scrollZoom': True})\n",
        "\n",
        "  folder='/content/drive/MyDrive/models/charts/'+ str(last_date)\n",
        "  Path(folder).mkdir(parents=True, exist_ok=True)\n",
        "  #print('chart folder:', folder)\n",
        "  fig.write_html(folder + '/' + ticker.ticker + '.html') \n",
        "  return fig"
      ],
      "metadata": {
        "id": "__5S41Y6xHQr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = yf.Ticker('PYPL')\n",
        "df = get_stock_price(ticker,\"2019-01-01\")\n",
        "\n",
        "macd, soch, rsi = indicators(df)\n",
        "dates = stock_data[:,0]\n",
        "\n",
        "rsi_array = rsi_data[:,1]\n",
        "stoch_slowD_array = stoch_data[:,1]\n",
        "stoch_slowK_array = stoch_data[:,2]\n",
        "macd_array = macd_data[:,1]\n",
        "macd_hist_array = macd_data[:,2]\n",
        "macd_signal_array = macd_data[:,3]\n",
        "\n",
        "indicators_data = np.append(np.expand_dims(dates, axis=1),  np.expand_dims(rsi_array, axis=1).astype(float),axis=1)\n",
        "indicators_data = np.append(indicators_data, np.expand_dims(stoch_slowD_array, axis=1),axis=1)\n",
        "indicators_data = np.append(indicators_data, np.expand_dims(stoch_slowK_array, axis=1),axis=1)\n",
        "indicators_data = np.append(indicators_data, np.expand_dims(macd_array, axis=1),axis=1)\n",
        "indicators_data = np.append(indicators_data, np.expand_dims(macd_hist_array, axis=1),axis=1)\n",
        "indicators_data = np.append(indicators_data, np.expand_dims(macd_signal_array, axis=1),axis=1)\n",
        "print('indicators_data',indicators_data[:5])\n",
        "\n",
        "rsi_df =pd.DataFrame(data=rsi.rsi()[1:,1:],    # values\n",
        "             index=rsi.rsi()[1:,0],    # 1st column as index\n",
        "             columns=rsi.rsi()[0,1:])  # 1st row as the column names\n",
        "\n",
        "#fig = get_chart(ticker, df, 365)\n",
        "#fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "3tsG8hRUQH8Y",
        "outputId": "6481fb3b-a2e3-4a65-ea25-6750b777793e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-ca5e57a5638c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmacd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindicators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m rsi_df =pd.DataFrame(data=rsi.rsi()[1:,1:],    # values\n\u001b[0m\u001b[1;32m      6\u001b[0m              \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrsi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0;31m# 1st column as index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m              columns=rsi.rsi()[0,1:])  # 1st row as the column names\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    919\u001b[0m             )\n\u001b[1;32m    920\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"key of type tuple not found and not a MultiIndex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;31m# If key is contained, would have returned by now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'key of type tuple not found and not a MultiIndex'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_charts(symbols):\n",
        "  for symbol in symbols:\n",
        "    ticker = yf.Ticker(symbol)\n",
        "    df = get_stock_price(ticker,\"2019-01-01\")\n",
        "    print(ticker.ticker,df.size)\n",
        "    get_chart(ticker, df, 365)\n",
        "    #time.sleep(5)\n",
        "  return None"
      ],
      "metadata": {
        "id": "6N7QKxi9Nqx8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbols = ['AAPL','AMD','AMZN','ABBV','ARKG','ARKK','ARKQ','ATVI',\n",
        "           'BA','CAT','CCL','CHPT','CHWY','COIN','CRM','DDOG',\n",
        "           'DIA','DIS','DKNG','DOCU','EA','ETSY','FB','GOOGL','HOG']\n",
        "\n",
        "symbols1 = ['HOOD','HUT','IWM','JAZZ','JETS','LVS','MA','MP',\n",
        "           'MRNA','MSFT','MSTR','MU','NCLH','NFLX','NKE','NNDM','NVDA']\n",
        "\n",
        "symbols2 = ['PFE','PINS','PLTR','PYPL','QQQ','RBLX','SPY',\n",
        "           'ROKU','SBUX','SHOP','SNAP','SOFI','SOXL','SOXX','SPY','SQ']\n",
        "\n",
        "symbols3 = ['TDOC','TEN','TGT','TLT','TSLA','TTD','TWTR','UAA',\n",
        "           'V','VTI','WBA','VALE','WMT','WYNN','XLE','XLF','XLNX','ZM']\n",
        "\n",
        "symbols4 = ['COST','RIVN','U','PENN','QCOM','RKLB','LCID','ASTR','BNGO','AAL','UBER','FRM']\n",
        "\n",
        "#save_charts(symbols)\n",
        "#save_charts(symbols1)\n",
        "#save_charts(symbols2)\n",
        "#save_charts(symbols3)\n",
        "#save_charts(symbols4)"
      ],
      "metadata": {
        "id": "CMcLhG4wzKd6"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}