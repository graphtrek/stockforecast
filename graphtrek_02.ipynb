{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "graphtrek_02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPl9Jw9IURND8ytOdH+9jZh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphtrek/stockforecast/blob/main/graphtrek_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLnu1v4MUcYn",
        "outputId": "28eca0bc-0201-40d2-c062-1937108130c4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGNwz2RC0ju9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "40361652-235b-4288-950c-d25a8a9c0590"
      },
      "source": [
        "# Test\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import requests\n",
        "import json\n",
        "import os, time\n",
        "\n",
        "from plotly.subplots import make_subplots\n",
        "from datetime import datetime, timedelta\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow import keras\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY7C0pUy0ok2"
      },
      "source": [
        "ticker = \"ZM\"\n",
        "look_back = 12\n",
        "stock_api_response = pd.read_json('https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol='+ticker+'&outputsize=full&apikey=3F4URDEKOPLFH25T')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlSmFyZwz5JC",
        "outputId": "d208c5bb-0aed-4831-cdaa-d82f761b8948"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "worksheet = gc.open('Stock Portfolio')\n",
        "rows = worksheet.get_worksheet(3).get_all_values()\n",
        "print(rows)\n",
        "\n",
        "\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "stocks_df = pd.DataFrame.from_records(rows)\n",
        "try :\n",
        "  nr_of_shares = stocks_df.loc[stocks_df[1] == ticker][8].values[0]\n",
        "  all_costs = stocks_df.loc[stocks_df[1] == ticker][9].values[0]\n",
        "  cost_per_share = stocks_df.loc[stocks_df[1] == ticker][10].values[0]\n",
        "except:\n",
        "  nr_of_shares = 0\n",
        "  all_costs = 0\n",
        "  cost_per_share = 0\n",
        "  \n",
        "print('Shares:', nr_of_shares,'Cost:',all_costs,'Cost Per Share:',cost_per_share)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Investment Category', 'Stock Ticker', 'Google Price', 'Manual Price', 'Last Price', 'Last DPS', 'Yield on Cost', 'Last Price Yield', 'Shares', 'Cost', 'Cost (Per Share)', 'Unrealized Gain/Loss', 'Unrealized Gain/Loss (%)', 'Realized Gain/Loss', 'Dividends Collected', 'Total Gain/Loss', 'Mkt Value'], ['Dividend', 'HOG', '37.22', '0.000', '37.22', '0.000', '0.00%', '0.00%', '10.0', '$397.90', '$39.79', '-$25.70', '-6.5%', '$0.00', '$0.00', '-$25.70', '$372.20'], ['Dividend', 'LVS', '38.22', '0.000', '38.22', '0.000', '0.00%', '0.00%', '20.0', '$853.25', '$42.66', '-$88.85', '-10.4%', '$0.00', '$0.00', '-$88.85', '$764.40'], ['Dividend', 'CAT', '195.16', '0.000', '195.16', '0.000', '0.00%', '0.00%', '5.0', '$996.90', '$199.38', '-$21.10', '-2.1%', '$0.00', '$0.00', '-$21.10', '$975.80'], ['Dividend', 'DIS', '176.74', '0.000', '176.74', '0.000', '0.00%', '0.00%', '6.0', '$1,059.44', '$176.57', '$1.00', '0.1%', '$0.00', '$0.00', '$1.00', '$1,060.44'], ['Dividend', 'CCL', '23.83', '0.000', '23.83', '0.000', '0.00%', '0.00%', '100.0', '$2,100.00', '$21.00', '$283.00', '13.5%', '$0.00', '$0.00', '$283.00', '$2,383.00'], ['Growth', 'PLTR', '23.5', '0.000', '23.5', '0.000', '0.00%', '0.00%', '20.0', '$429.50', '$21.48', '$40.50', '9.4%', '$0.00', '$0.00', '$40.50', '$470.00'], ['Dividend', 'WBA', '47.38', '0.000', '47.38', '0.000', '0.00%', '0.00%', '15.0', '$686.75', '$45.78', '$23.95', '3.5%', '$0.00', '$0.00', '$23.95', '$710.70'], ['Dividend', 'JETS', '23.98', '0.000', '23.98', '0.000', '0.00%', '0.00%', '20.0', '$434.00', '$21.70', '$45.60', '10.5%', '$0.00', '$0.00', '$45.60', '$479.60'], ['Growth', 'TSLA', '785.49', '0.000', '785.49', '0.000', '0.00%', '0.00%', '17.0', '$11,996.59', '$705.68', '$1,356.74', '11.3%', '$54.31', '$0.00', '$1,411.05', '$13,353.33'], ['Value', 'AMZN', '3288.62', '0.000', '3288.62', '0.000', '0.00%', '0.00%', '1.0', '$3,365.00', '$3,365.00', '-$76.38', '-2.3%', '$0.00', '$0.00', '-$76.38', '$3,288.62'], ['Dividend', 'ATVI', '77.61', '0.000', '77.61', '0.000', '0.00%', '0.00%', '15.0', '$1,200.50', '$80.03', '-$36.35', '-3.0%', '$0.00', '$0.00', '-$36.35', '$1,164.15'], ['Value', 'ETSY', '212.02', '0.000', '212.02', '0.000', '0.00%', '0.00%', '4.0', '$710.00', '$177.50', '$138.08', '19.4%', '$0.00', '$0.00', '$138.08', '$848.08'], ['Dividend', 'LOGI', '87.85', '0.000', '87.85', '0.000', '0.00%', '0.00%', '10.0', '$1,040.00', '$104.00', '-$161.50', '-15.5%', '$0.00', '$0.00', '-$161.50', '$878.50'], ['Value', 'JAZZ', '135.97', '0.000', '135.97', '0.000', '0.00%', '0.00%', '10.0', '$1,395.00', '$139.50', '-$35.30', '-2.5%', '$0.00', '$0.00', '-$35.30', '$1,359.70'], ['Value', 'U', '136.22', '0.000', '136.22', '0.000', '0.00%', '0.00%', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$130.00', '$0.00', '$130.00', '$0.00'], ['Dividend', 'MU', '70.12', '0.000', '70.12', '0.000', '0.00%', '0.00%', '9.0', '$629.58', '$69.95', '$1.50', '0.2%', '$0.00', '$0.00', '$1.50', '$631.08'], ['Special Situation', 'FFND', '24.97', '0.000', '24.97', '0.000', '0.00%', '0.00%', '10.0', '$254.80', '$25.48', '-$5.10', '-2.0%', '$0.00', '$0.00', '-$5.10', '$249.70'], ['Value', 'ZM', '255.05', '0.000', '255.05', '0.000', '0.00%', '0.00%', '4.0', '$1,188.32', '$297.08', '-$168.12', '-14.1%', '$0.00', '$0.00', '-$168.12', '$1,020.20'], ['Dividend', 'ABBV', '111.18', '0.000', '111.18', '0.000', '0.00%', '0.00%', '5.0', '$549.50', '$109.90', '$6.40', '1.2%', '$0.00', '$0.00', '$6.40', '$555.90'], ['Dividend', 'V', '230.27', '0.000', '230.27', '0.000', '0.00%', '0.00%', '4.0', '$898.50', '$224.63', '$22.58', '2.5%', '$0.00', '$0.00', '$22.58', '$921.08'], ['Growth', 'RKLB', '14.71', '0.000', '14.71', '0.000', '0.00%', '0.00%', '100.0', '$1,400.00', '$14.00', '$71.00', '5.1%', '$0.00', '$0.00', '$71.00', '$1,471.00'], ['Growth', 'CHWY', '62.6', '0.000', '62.6', '0.000', '0.00%', '0.00%', '10.0', '$711.42', '$71.14', '-$85.42', '-12.0%', '$0.00', '$0.00', '-$85.42', '$626.00'], ['Dividend', 'VTI', '226.39', '0.000', '226.39', '0.000', '0.00%', '0.00%', '5.0', '$1,137.78', '$227.56', '-$5.83', '-0.5%', '$0.00', '$0.00', '-$5.83', '$1,131.95'], ['Dividend', 'SPY', '437.86', '0.000', '437.86', '0.000', '0.00%', '0.00%', '4.0', '$1,756.70', '$439.18', '-$5.26', '-0.3%', '$0.00', '$0.00', '-$5.26', '$1,751.44'], ['Growth', 'ASTR', '7.83', '0.000', '7.83', '0.000', '0.00%', '0.00%', '100.0', '$1,000.00', '$10.00', '-$217.00', '-21.7%', '$0.00', '$0.00', '-$217.00', '$783.00'], ['Dividend', 'QQQ', '361.16', '0.000', '361.16', '0.000', '0.00%', '0.00%', '3.0', '$1,082.81', '$360.94', '$0.67', '0.1%', '$0.00', '$0.00', '$0.67', '$1,083.48'], ['Dividend', 'NKE', '152.48', '0.000', '152.48', '0.000', '0.00%', '0.00%', '2.0', '$295.56', '$147.78', '$9.40', '3.2%', '$0.00', '$0.00', '$9.40', '$304.96'], ['Growth', 'FB', '330.05', '0.000', '330.05', '0.000', '0.00%', '0.00%', '2.0', '$670.00', '$335.00', '-$9.90', '-1.5%', '$0.00', '$0.00', '-$9.90', '$660.10'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '0.000', '0', '0.000', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00'], ['', '', 'No Data', '', '', '', '0.00%', '-', '0.0', '$0.00', '$0.00', '$0.00', '0.0%', '$0.00', '$0.00', '$0.00', '$0.00']]\n",
            "Shares: 4.0 Cost: $1,188.32 Cost Per Share: $297.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHAGynG_002r"
      },
      "source": [
        "stock_api_data = stock_api_response['Time Series (Daily)']\n",
        "#print(stock_api_data)\n",
        "stock_api_data = stock_api_data.drop(index=['1. Information','2. Symbol','3. Last Refreshed','4. Output Size','5. Time Zone']);\n",
        "#print(list(stock_api_data.items()))\n",
        "data = []\n",
        "for key, value in stock_api_data.items():\n",
        "  data.append([\n",
        "      pd.to_datetime(key,).date(),\n",
        "      value.get('1. open'),\n",
        "      value.get('2. high'),\n",
        "      value.get('3. low'),\n",
        "      value.get('5. adjusted close'),\n",
        "      value.get('6. volume')\n",
        "      ])\n",
        "\n",
        "last_data =  str(data[0][0])\n",
        "print(data[0])\n",
        "data = np.flip(data[:1000],axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWJQCTCLhSd_"
      },
      "source": [
        "model = None\n",
        "model_file_path = '/content/drive/MyDrive/models/'+ticker+'.h5'\n",
        "try:\n",
        "  model = keras.models.load_model(model_file_path)\n",
        "  modified = os.path.getmtime(model_file_path)\n",
        "\n",
        "  print(data[0][0] - datetime.fromtimestamp(modified).date() )\n",
        "  print('Loaded', ticker , 'model train date:',datetime.fromtimestamp(modified).date() , 'last data:', last_data)\n",
        "except:\n",
        "  model = None\n",
        "  print('Model ' + ticker + ' does not exists.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWoEPPGX3g-F"
      },
      "source": [
        "df = pd.DataFrame(data,columns=['Date','Open','High','Low','Close','Volume'])\n",
        "\n",
        "df['50MA'] = df['Close'].rolling(50).mean()\n",
        "df['100MA'] = df['Close'].rolling(100).mean()\n",
        "df['200MA'] = df['Close'].rolling(200).mean()\n",
        "\n",
        "split_percent = 0.90\n",
        "split = int(split_percent*len(data))\n",
        "\n",
        "split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5xI5TD06BzU"
      },
      "source": [
        "close_data = df['Close'].values\n",
        "close_data = np.asarray(close_data).astype(np.float32)\n",
        "close_data = close_data.reshape((-1))\n",
        "\n",
        "train_data = close_data[:split]\n",
        "test_data = close_data[split:]\n",
        "\n",
        "train_dates = df['Date'][:split]\n",
        "test_dates = df['Date'][split:]\n",
        "\n",
        "volumes = np.asarray(df['Volume'].values).astype(np.int)[-150:]\n",
        "volume_dates = df['Date'][-150:]\n",
        "#len(test_data), test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YT50B6aO7Iv5"
      },
      "source": [
        "trace1 = go.Scatter(\n",
        "    x = train_dates,\n",
        "    y = train_data,\n",
        "    mode = 'lines',\n",
        "    line=dict(width=3),\n",
        "    name = 'Train'\n",
        ")\n",
        "\n",
        "trace2 = go.Scatter(\n",
        "    x = test_dates,\n",
        "    y = test_data,\n",
        "    mode='lines',\n",
        "    line=dict(width=3),\n",
        "    name ='Test'\n",
        ")\n",
        "\n",
        "trace3 = go.Scatter(\n",
        "    x = df['Date'],\n",
        "    y = df['50MA'],\n",
        "    mode='lines',\n",
        "    name ='50MA'\n",
        ")\n",
        "\n",
        "trace4 = go.Scatter(\n",
        "    x = df['Date'],\n",
        "    y = df['100MA'],\n",
        "    mode='lines',\n",
        "    name ='100MA'\n",
        ")\n",
        "\n",
        "trace5 = go.Scatter(\n",
        "    x = df['Date'],\n",
        "    y = df['200MA'],\n",
        "    mode='lines',\n",
        "    name ='200MA'\n",
        ")\n",
        "\n",
        "layout = go.Layout(\n",
        "    title = ticker + ' Date:' + last_data + ' Open:' + str(data[-1][1]) + ' High:' + str(data[-1][2]) + ' Low:' + str(data[-1][3]) + ' Close:' + str(data[-1][4]),\n",
        "    xaxis = {'title' : \"Dates\"},\n",
        "    yaxis = {'title' : \"Close Price ($)\"},\n",
        "    height = 450\n",
        ")\n",
        "fig = go.Figure(data=[trace1, trace2, trace3, trace4, trace5], layout=layout)\n",
        "fig.show()\n",
        "\n",
        "\n",
        "fig = px.area(x=volume_dates, y=volumes, height=250, labels={\n",
        "                     \"x\": \"Dates\",\n",
        "                     \"y\": \"Volume\"\n",
        "                 },\n",
        "                title=ticker)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_YXc0z-94UO"
      },
      "source": [
        "# Normalizing data, scale between 0 and 1:\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0, 1))\n",
        "train_data_scaled = sc.fit_transform(train_data.reshape((-1,1)))\n",
        "test_data_scaled = sc.fit_transform(test_data.reshape((-1,1)))\n",
        "train_data_scaled.shape, test_data_scaled.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyF4LvOcBqdM"
      },
      "source": [
        "if model is None:\n",
        "  # Building Model:\n",
        "  # The LSTM layer expects the number of time steps and the number of features to work properly.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.LSTM(units=50, return_sequences=True, activation=\"tanh\",\n",
        "                                input_shape=(look_back, 1)))\n",
        "\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "  model.add(tf.keras.layers.LSTM(units=50, return_sequences=True, activation=\"tanh\"))\n",
        "\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "  model.add(tf.keras.layers.LSTM(units=50, return_sequences=True, activation=\"tanh\"))\n",
        "\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "  model.add(tf.keras.layers.LSTM(units=50, activation=\"tanh\"))\n",
        "\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "  model.add(tf.keras.layers.Dense(units=1))\n",
        "\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.MAE,\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "      metrics=[\"mae\"]\n",
        "  )\n",
        "  \n",
        "  print('Model ' + ticker + ' compiled.')\n",
        "\n",
        "  train_generator = TimeseriesGenerator(train_data_scaled, train_data_scaled, length=look_back)     \n",
        "  \n",
        "  modelo = model.fit(train_generator, epochs=100, verbose=0)\n",
        "  model.save(model_file_path)\n",
        "  print('Saved model ' + ticker)\n",
        "\n",
        "  plt.plot(modelo.history['loss'])\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z32sIk3cCkVP"
      },
      "source": [
        "test_generator = TimeseriesGenerator(test_data_scaled, test_data_scaled, length=look_back)\n",
        "predicted_stock_price_scaled = model.predict(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7exB2tCVDKGl"
      },
      "source": [
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price_scaled)\n",
        "zoom = 700\n",
        "trace1 = go.Scatter(\n",
        "    x = train_dates[zoom:],\n",
        "    y = train_data[zoom:],\n",
        "    mode = 'lines',\n",
        "    name = 'Train'\n",
        ")\n",
        "trace2 = go.Scatter(\n",
        "    x = test_dates,\n",
        "    y = test_data,\n",
        "    mode='lines',\n",
        "    name = 'Test'\n",
        ")\n",
        "trace3 = go.Scatter(\n",
        "    x = test_dates,\n",
        "    y = predicted_stock_price.reshape((-1)),\n",
        "    mode='lines',\n",
        "    line=dict(width=3),\n",
        "    name = 'Predict'\n",
        ")\n",
        "layout = go.Layout(\n",
        "    title = ticker + ' Date:' + last_data + ' Open:' + str(data[-1][1]) + ' High:' + str(data[-1][2]) + ' Low:' + str(data[-1][3]) + ' Close:' + str(data[-1][4]),\n",
        "    xaxis = {'title' : \"Dates\"},\n",
        "    yaxis = {'title' : \"Close Price ($)\"},\n",
        "    height = 600\n",
        ")\n",
        "fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n",
        "fig.show()\n",
        "fig.write_html('/content/drive/MyDrive/models/'+ticker+ '_' + last_data + '_predict.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtwieH7SJj_v"
      },
      "source": [
        "def predict(num_prediction, model):\n",
        "    prediction_list = test_data_scaled[-look_back:]\n",
        "    \n",
        "    for _ in range(num_prediction):\n",
        "        x = prediction_list[-look_back:]\n",
        "        x = x.reshape((1, look_back, 1))\n",
        "        out = model.predict(x)[0][0]\n",
        "        prediction_list = np.append(prediction_list, out)\n",
        "    prediction_list = prediction_list[look_back-1:]\n",
        "        \n",
        "    return prediction_list\n",
        "    \n",
        "def predict_dates(num_prediction):\n",
        "    last_date = df['Date'].values[-1]\n",
        "    prediction_dates = pd.date_range(last_date, periods=num_prediction+1).tolist()\n",
        "    return prediction_dates\n",
        "\n",
        "num_prediction = look_back\n",
        "forecast_scaled = predict(num_prediction, model)\n",
        "forecast_dates = predict_dates(num_prediction)\n",
        "\n",
        "forecast = sc.inverse_transform(forecast_scaled.reshape((-1,1)))\n",
        "#forecast_dates,forecast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip62GCoJLduZ"
      },
      "source": [
        "zoom = 850\n",
        "\n",
        "trace1 = go.Candlestick(\n",
        "    x = train_dates[zoom:],\n",
        "    open = df['Open'].values[zoom:],\n",
        "    high = df['High'].values[zoom:],\n",
        "    low = df['Low'].values[zoom:],\n",
        "    close = train_data[zoom:],\n",
        "#    mode = 'lines',\n",
        "#    line=dict(width=3),\n",
        "    name = 'Train'\n",
        ")\n",
        "trace2 = go.Candlestick(\n",
        "    x = test_dates,\n",
        "    open = df['Open'].values[split:],\n",
        "    high = df['High'].values[split:],\n",
        "    low = df['Low'].values[split:],\n",
        "    close = test_data,\n",
        "#    mode='lines',\n",
        "#    line=dict(width=3),\n",
        "    name = 'Test'\n",
        ")\n",
        "trace3 = go.Scatter(\n",
        "    x = test_dates,\n",
        "    y = predicted_stock_price.reshape((-1)),\n",
        "    mode='lines',\n",
        "    name = 'Predict'\n",
        ")\n",
        "trace4 = go.Scatter(\n",
        "    x = forecast_dates,\n",
        "    y = forecast.reshape((-1)),\n",
        "    mode='lines',\n",
        "    line=dict(width=3),\n",
        "    name = 'Forecast'\n",
        ")\n",
        "trace5 = go.Scatter(\n",
        "    x = df['Date'][zoom:],\n",
        "    y = df['50MA'][zoom:],\n",
        "    mode='lines',\n",
        "    name ='50MA'\n",
        ")\n",
        "trace6 = go.Scatter(\n",
        "    x = df['Date'][zoom:],\n",
        "    y = df['100MA'][zoom:],\n",
        "    mode='lines',\n",
        "    name ='100MA'\n",
        ")\n",
        "trace7 = go.Scatter(\n",
        "    x = df['Date'][zoom:],\n",
        "    y = df['200MA'][zoom:],\n",
        "    mode='lines',\n",
        "    name ='200MA'\n",
        ")\n",
        "\n",
        "\n",
        "print('Shares:', nr_of_shares,'Cost:',all_costs,'Cost Per Share:', cost_per_share, '50MA:', int(df['50MA'].values[-1]))\n",
        "print('Forecast:',forecast.reshape((-1)).astype(np.int))\n",
        "layout = go.Layout(\n",
        "    title = \n",
        "    '<b>'+ticker+ '</b>' + ' Date:' + last_data + '<BR>' \n",
        "    'Open:' + str(data[-1][1]) + \n",
        "    ' High:' + str(data[-1][2]) + \n",
        "    ' Low:' + str(data[-1][3]) + \n",
        "    ' Close:' + str(data[-1][4]) + \n",
        "    ' ' +\n",
        "    'Forecast in ' + str(len(forecast_dates)) + ' days ' + str(np.around(forecast.mean())) + \n",
        "    '<BR>' + \n",
        "    'Shares:' + str(nr_of_shares) +\n",
        "    ' Cost: ' + str(all_costs).replace('$','') +\n",
        "    ' Cost Per Share: ' + str(cost_per_share).replace('$',''),\n",
        "    xaxis = {'title' : 'Dates'},\n",
        "    yaxis = {'title' : 'Close Price ($)'},\n",
        "    height = 600,\n",
        "    font=dict(\n",
        "        family=\"Courier New, monospace\",\n",
        "        size=8,\n",
        "        color=\"#7f7f7f\"\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "fig = go.Figure(data=[trace1, trace2, trace3, trace4, trace5, trace6, trace7], layout=layout)\n",
        "\n",
        "fig.update_yaxes(showspikes=True, spikemode='across', spikesnap='cursor',spikedash='dash')\n",
        "fig.update_xaxes(showspikes=True, spikemode='across', spikesnap='cursor', spikedash='dash')\n",
        "fig.update_layout(xaxis_rangeslider_visible=False)\n",
        "\n",
        "\n",
        "\n",
        "config = dict({'scrollZoom': True})\n",
        "fig.show(config=config)\n",
        "\n",
        "fig.write_html('/content/drive/MyDrive/models/'+ticker+ '_' + last_data + '_forecast.html')\n",
        "\n",
        "fig = px.area(x=volume_dates, y=volumes, height=250, labels={\n",
        "                     \"x\": \"Dates\",\n",
        "                     \"y\": \"Volume\"\n",
        "                 },\n",
        "                title=ticker)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}